{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPSS Object Size Distribution\n",
    "\n",
    "Generate histograms of object size and object mass of all data objects in NERSC's 200 PB HPSS tape archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.config\n",
    "import dask.bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.diagnostics\n",
    "dask.diagnostics.ProgressBar().register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.set(scheduler='processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = 'hpss_file_sizes_20201016.log'\n",
    "INPUT_CACHE = 'hpss_file_sizes_20201016-*.log.gz'\n",
    "OUTPUT_HIST_CSV = \"hpss_file_size_hist_20201016.csv\"\n",
    "\n",
    "CSCRATCH_DIST = 'cscratch_20190115_sizebytype_hist.csv'\n",
    "PROJECT2_DIST = 'tlproject2_20181109_sizebytype_hist.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(line):\n",
    "    \"\"\"Converts the raw DB2 dump to a simple list of sizes.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(line.strip())\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def binner(value):\n",
    "    \"\"\"Bins each object size.  Start of each bin is inclusive.\n",
    "    \"\"\"\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    return int(math.log(value, 2)) + 1\n",
    "\n",
    "def humanscale(value):\n",
    "    \"\"\"Converts a base-2 number into a human-readable measure of size.\n",
    "    \"\"\"\n",
    "    SCALES = [\n",
    "        (2**50, \"PiB\"),\n",
    "        (2**40, \"TiB\"),\n",
    "        (2**30, \"GiB\"),\n",
    "        (2**20, \"MiB\"),\n",
    "        (2**10, \"KiB\"),\n",
    "    ]\n",
    "    for scale in SCALES:\n",
    "        if value >= scale[0]:\n",
    "            return \"%d %s\" % (value / scale[0], scale[1])\n",
    "    return \"%d\" % int(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either read the input file and generate an input cache, or read the cache if it exists\n",
    "if (glob.glob(INPUT_CACHE)):\n",
    "    print(\"Loading %s from cache\" % INPUT_CACHE)\n",
    "    db = dask.bag.read_text(INPUT_CACHE).map(int)\n",
    "else:\n",
    "    print(\"Loading %s from raw input\" % INPUT_FILE)\n",
    "    db = dask.bag.read_text(INPUT_FILE).map(mapper).filter(lambda x: x is not None)\n",
    "    print(\"Writing out %s\" % INPUT_CACHE)\n",
    "    db.map(str).to_textfiles(INPUT_CACHE)\n",
    "    \n",
    "# Convert read data into a DataFrame\n",
    "dd = db.to_dataframe(columns=[\"size (bytes)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Histograms\n",
    "\n",
    "Bins all objects based on their size, then aggregates bins based on object count and sum of sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd['bin num'] = dd['size (bytes)'].map(binner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dd.groupby('bin num')\n",
    "dataframe = dataframe.agg(['count', 'sum']).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['bin start'] = dataframe.index.map(lambda x: 2**(x - 1) if x > 0 else 0)\n",
    "dataframe['bin start (human)'] = dataframe['bin start'].map(humanscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMAP_COLS = {\n",
    "    'size (bytes) count': 'object count',\n",
    "    'size (bytes) sum': 'object size sum (bytes)'\n",
    "}\n",
    "\n",
    "dataframe.columns = [' '.join(col).strip() for col in dataframe.columns.values]\n",
    "dataframe.columns = list([REMAP_COLS.get(x, x) for x in dataframe.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['object count cumul sum'] = dataframe['object count'].cumsum()\n",
    "dataframe['object size cumul sum (bytes)'] = dataframe['object size sum (bytes)'].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "\n",
    "ax.bar(dataframe.index, dataframe['object count'] / 1e6, width=1, edgecolor='black')\n",
    "ax.grid()\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_ylabel(\"Millions of objects\")\n",
    "ax.set_xlabel(\"Object Size\")\n",
    "ax.set_xticks(dataframe.index[::8])\n",
    "ax.set_xticklabels(dataframe['bin start (human)'][::8], rotation=30, ha='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "\n",
    "ax.bar(dataframe.index, dataframe['object size sum (bytes)'] / 2**50, width=1, edgecolor='black')\n",
    "ax.grid()\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_ylabel(\"Petabytes of data\")\n",
    "ax.set_xlabel(\"Object Size\")\n",
    "ax.set_xticks(dataframe.index[::8])\n",
    "ax.set_xticklabels(dataframe['bin start (human)'][::8], rotation=30, ha='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "\n",
    "ax.plot(dataframe.index, dataframe['object count cumul sum'] / dataframe['object count cumul sum'].iloc[-1])\n",
    "ax.grid()\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_ylabel(\"Cumulative fraction of all objects\")\n",
    "ax.set_xlabel(\"Object Size\")\n",
    "ax.set_xticks(dataframe.index[::8])\n",
    "ax.set_xticklabels(dataframe['bin start (human)'][::8], rotation=30, ha='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "\n",
    "ax.plot(dataframe.index, dataframe['object size cumul sum (bytes)'] / dataframe['object size cumul sum (bytes)'].iloc[-1])\n",
    "ax.grid()\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_ylabel(\"Cumulative fraction of data\")\n",
    "ax.set_xlabel(\"Object Size\")\n",
    "ax.set_xticks(dataframe.index[::8])\n",
    "ax.set_xticklabels(dataframe['bin start (human)'][::8], rotation=30, ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display/save numeric histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv(OUTPUT_HIST_CSV)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to file systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cscratch_hist = pandas.read_csv(CSCRATCH_DIST)[['bin_size', 'num_files']][1:]\n",
    "except FileNotFoundError:\n",
    "    cscratch_hist = None\n",
    "    \n",
    "if cscratch_hist is not None:\n",
    "    cscratch_hist.columns = ['bin start', 'object count']\n",
    "    cscratch_hist.index.name = \"bin num\"\n",
    "    # note we have to alter the bins since the fs datasets label bins according to their inclusive ends, not inclusive starts\n",
    "    cscratch_hist['bin start'].map(lambda x: int(x/2.0))\n",
    "    cscratch_hist['object count cumul sum'] = cscratch_hist['object count'].cumsum()\n",
    "    cscratch_hist['bin start (human)'] = cscratch_hist['bin start'].map(humanscale)\n",
    "    cscratch_hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    project2_hist = pandas.read_csv(PROJECT2_DIST)[['bin_size', 'num_files']][1:]\n",
    "except FileNotFoundError:\n",
    "    project2_hist = None\n",
    "\n",
    "if project2_hist is not None:\n",
    "    project2_hist.columns = ['bin start', 'object count']\n",
    "    project2_hist.index.name = \"bin num\"\n",
    "    # note we have to alter the bins since the fs datasets label bins according to their inclusive ends, not inclusive starts\n",
    "    project2_hist['bin start'].map(lambda x: int(x/2.0))\n",
    "    project2_hist['object count cumul sum'] = project2_hist['object count'].cumsum()\n",
    "    project2_hist['bin start (human)'] = project2_hist['bin start'].map(humanscale)\n",
    "    project2_hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = matplotlib.pyplot.subplots(figsize=(8,4))\n",
    "\n",
    "ax.plot(dataframe.index, dataframe['object count cumul sum'] / dataframe['object count cumul sum'].iloc[-1], label=\"Tape Archive (Oct 2020)\")\n",
    "if cscratch_hist is not None:\n",
    "    ax.plot(cscratch_hist.index, cscratch_hist['object count cumul sum'] / cscratch_hist['object count cumul sum'].iloc[-1], label=\"Lustre Scratch (Jan 2019)\")\n",
    "if project2_hist is not None:\n",
    "    ax.plot(project2_hist.index, project2_hist['object count cumul sum'] / project2_hist['object count cumul sum'].iloc[-1], label=\"GPFS Project (Nov 2018)\")\n",
    "ax.grid()\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_ylabel(\"Cumulative fraction of all objects\")\n",
    "ax.set_xlabel(\"Object Size\")\n",
    "ax.set_xticks(dataframe.index[::8])\n",
    "ax.set_xticklabels(dataframe['bin start (human)'][::8], rotation=30, ha='right')\n",
    "ax.legend()\n",
    "ax.set_xlim(0, 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
